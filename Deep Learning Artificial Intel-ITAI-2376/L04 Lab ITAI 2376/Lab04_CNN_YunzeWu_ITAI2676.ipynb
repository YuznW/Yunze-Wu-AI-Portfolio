{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Building a CNN for MNIST Handwritten Digit Classification\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome! In this assignment, you will build a Convolutional Neural Network (CNN) to classify handwritten digits from the famous MNIST dataset. This dataset is a classic in the field of computer vision and provides a great starting point for understanding image classification with deep learning.\n",
        "\n",
        "This notebook is structured to guide you step-by-step through the process. You will load the data, preprocess it, define a CNN model, train it, and evaluate its performance.  Throughout the assignment, you will have opportunities to experiment and deepen your understanding of the concepts.\n",
        "\n",
        "Remember to:\n",
        "\n",
        "*   **Read all instructions carefully.**\n",
        "*   **Execute the code cells in order.**\n",
        "*   **Fill in the missing code sections marked as \"Students: Fill in the blanks\".**\n",
        "*   **Answer the reflection questions in the designated Markdown cell.**\n",
        "*   **Experiment and explore!**  Change parameters, layers, and observe the effects.\n",
        "\n",
        "Let's get started and build our MNIST digit classifier!\n",
        "\n",
        "## Section 1: Setting Up - Imports\n",
        "\n",
        "Before we dive into building our CNN, we need to import the necessary libraries.  These libraries provide pre-built tools and functions that will make our work much easier.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully review the code cell below.** It imports libraries from TensorFlow and Keras, which are powerful frameworks for building and training neural networks.\n",
        "2.  **Execute the code cell by selecting it and pressing [Shift + Enter] (or the \"Run\" button).**\n",
        "3.  **Ensure there are no error messages after running the cell.** If you encounter errors, double-check that you have TensorFlow and Keras installed in your environment."
      ],
      "metadata": {
        "id": "fK46PtzUyabH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xN_gVhnXyabK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Imports:**\n",
        "\n",
        "*   **`tensorflow as tf` and `keras`:** TensorFlow is the main deep learning framework, and Keras is its high-level API that simplifies building and training models. We import TensorFlow as `tf` and Keras directly for easy access to their functionalities.\n",
        "*   **`from tensorflow.keras import layers`:**  This imports the `layers` module from Keras, which provides various layers for building neural networks (like convolutional layers, dense layers, etc.).\n",
        "*   **`from tensorflow.keras.datasets import mnist`:**  This imports the MNIST dataset directly from Keras datasets.  This is very convenient for loading and using the MNIST data.\n",
        "*   **`from tensorflow.keras.utils import to_categorical`:**  This imports the `to_categorical` function, which we will use to perform one-hot encoding of our labels.\n",
        "\n",
        "## Section 2: Data Loading and Preprocessing\n",
        "\n",
        "In this section, we will load the MNIST dataset and prepare it for training our CNN model.  Preprocessing steps are crucial to ensure our data is in the right format for the model to learn effectively.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Read through the code in the cell below.**  Understand how it loads the MNIST dataset and what preprocessing steps are applied.\n",
        "2.  **Execute the code cell.**\n",
        "3.  **Examine the comments in the code** to understand each preprocessing step in detail."
      ],
      "metadata": {
        "id": "jXAItJ1RyabL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Loading and Preprocessing\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Add a channel dimension (for grayscale images, it's 1)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "OCi441G0yabL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8bd10f-11a9-49a9-9429-b81d64159d2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Data Preprocessing:**\n",
        "\n",
        "*   **Loading the MNIST dataset:** `mnist.load_data()` loads the MNIST dataset, which is already split into training and testing sets (`(x_train, y_train), (x_test, y_test)`). `x_train` and `x_test` contain the images (pixel data), and `y_train` and `y_test` contain the corresponding labels (digits 0-9).\n",
        "*   **Normalization:** `x_train = x_train.astype(\"float32\") / 255.0` and `x_test = x_test.astype(\"float32\") / 255.0` normalize the pixel values.  Pixel values in images are typically in the range 0-255. Dividing by 255 scales them to the range 0-1. This normalization helps the neural network train faster and more effectively.\n",
        "*   **Adding Channel Dimension:** `x_train = x_train.reshape(-1, 28, 28, 1)` and `x_test = x_test.reshape(-1, 28, 28, 1)` reshape the data to add a channel dimension.  Even though MNIST images are grayscale (single channel), CNNs in Keras expect input data to have a channel dimension.  We reshape from `(number_of_images, 28, 28)` to `(number_of_images, 28, 28, 1)`. The `-1` in `reshape` means \"infer the dimension based on the size of the array.\"\n",
        "*   **One-Hot Encoding:** `y_train = to_categorical(y_train, num_classes)` and `y_test = to_categorical(y_test, num_classes)` perform one-hot encoding on the labels.  Instead of representing the digit '3' as a single number, one-hot encoding converts it into a vector `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, where the 4th position (index 3) is 'hot' (value 1), and all other positions are 'cold' (value 0). This is a standard way to represent categorical labels for neural networks in multi-class classification problems. `num_classes = 10` specifies that we have 10 classes (digits 0-9).\n",
        "\n",
        "## Section 3: Model Definition - Building the CNN\n",
        "\n",
        "Now we will define the architecture of our Convolutional Neural Network (CNN).  You will be building a sequential model using Keras layers.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully examine the code in the cell below.** Notice the structure of the `keras.Sequential` model.\n",
        "2.  **Fill in the missing parts** marked with `# Students: Fill in the blanks` to complete the model definition.\n",
        "3.  **Experiment!** You are encouraged to try different configurations for the layers, such as changing the number of filters in the convolutional layers, or adding more layers."
      ],
      "metadata": {
        "id": "UNkWB4hvyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Model Definition\n",
        "# Build the CNN model.  Students: Fill in the missing parts!\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),  # Input layer\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 1\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 1\n",
        "        # Students: Add another Conv2D layer here.  Experiment with the number of filters!\n",
        "        # layers.Conv2D(____, kernel_size=(____, ____), activation=\"____\"),  # Convolutional layer 2\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 2\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 2\n",
        "        # Students: Add another MaxPooling2D layer here if needed.\n",
        "        # layers.MaxPooling2D(pool_size=(____, ____)),  # Max pooling layer 2\n",
        "        layers.Flatten(),  # Flatten layer\n",
        "        layers.Dropout(0.5),  # Dropout layer\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),  # Output layer\n",
        "    ]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FFOe2fviyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Layers:**\n",
        "\n",
        "*   **`keras.Input(shape=(28, 28, 1))`:** This is the input layer of our model. It specifies the shape of the input images, which are 28x28 pixels with 1 channel (grayscale).\n",
        "*   **`layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")`:** This is a 2D Convolutional layer.\n",
        "    *   `32`: This is the number of filters (also called kernels). Each filter learns to detect specific features in the input image.\n",
        "    *   `kernel_size=(3, 3)`: This defines the size of the convolutional filter as 3x3 pixels.\n",
        "    *   `activation=\"relu\"`:  ReLU (Rectified Linear Unit) is the activation function. It introduces non-linearity into the model, allowing it to learn complex patterns.\n",
        "*   **`layers.MaxPooling2D(pool_size=(2, 2))`:** This is a Max Pooling layer.\n",
        "    *   `pool_size=(2, 2)`:  It reduces the spatial dimensions of the feature maps by taking the maximum value within each 2x2 window. This helps to reduce the number of parameters, control overfitting, and make the model more robust to small shifts and distortions in the input.\n",
        "*   **`layers.Flatten()`:** This layer flattens the 2D feature maps from the convolutional and pooling layers into a 1D vector. This is necessary to connect the convolutional part of the network to the fully connected (Dense) layers.\n",
        "*   **`layers.Dropout(0.5)`:** This is a Dropout layer.\n",
        "    *   `0.5`: This sets the dropout rate to 50%. During training, this layer randomly sets 50% of the input units to 0 at each update. This is a regularization technique that helps to prevent overfitting.\n",
        "*   **`layers.Dense(num_classes, activation=\"softmax\")`:** This is the output Dense (fully connected) layer.\n",
        "    *   `num_classes`:  This is set to 10 because we have 10 classes (digits 0-9).\n",
        "    *   `activation=\"softmax\"`: Softmax activation ensures that the output values are probabilities, and they sum up to 1 across all classes.  The output will be a vector of 10 probabilities, where each probability represents the model's confidence that the input image belongs to that specific digit class.\n",
        "\n",
        "## Section 4: Model Compilation - Choosing Loss and Optimizer\n",
        "\n",
        "Before we can train our model, we need to compile it.  Compilation involves choosing an optimizer, a loss function, and metrics to evaluate the model's performance.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for the `loss` and `optimizer` parameters in `model.compile()`.\n",
        "2.  **Choose an appropriate loss function and optimizer** for this multi-class classification problem.\n",
        "3.  **In the Markdown cell after the code, explain your choices.** Why are these choices suitable for this task?"
      ],
      "metadata": {
        "id": "-x0iiCewyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Model Compilation\n",
        "# Students: Choose an appropriate loss function and optimizer.  Why did you choose these?\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) #Students: Fill in the blanks"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YVr-ooXfyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Choices (To be filled by students in the reflection section):**\n",
        "\n",
        "*   **Loss Function:** You need to choose a loss function that is appropriate for multi-class classification. Think about what kind of error we are trying to minimize when classifying digits into 10 categories.\n",
        "*   **Optimizer:** You need to choose an optimizer that will efficiently update the model's weights to minimize the loss function.  Consider common optimizers used in deep learning.\n",
        "*   **Metrics:** We are using \"accuracy\" as a metric to evaluate the model's performance. Accuracy is a common metric for classification tasks, representing the percentage of correctly classified images.\n",
        "\n",
        "## Section 5: Model Training - Fitting the Model to the Data\n",
        "\n",
        "Now it's time to train our CNN model using the training data. Training involves feeding the training data to the model and adjusting its weights to minimize the loss function.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for `batch_size` and `epochs` in `model.fit()`.\n",
        "2.  **Choose appropriate values for `batch_size` and `epochs`.**\n",
        "3.  **Run the code cell to start training.** Observe the training progress, especially the loss and accuracy on both the training and validation sets.\n",
        "4.  **Experiment!** Change the `batch_size` and `epochs` and see how it affects the training process and the final performance."
      ],
      "metadata": {
        "id": "2R7iy69RyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Model Training\n",
        "# Students: Adjust the batch size and number of epochs.  What happens if you change them?\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1) #Students: Fill in the blanks"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - accuracy: 0.7669 - loss: 0.7491 - val_accuracy: 0.9762 - val_loss: 0.0920\n",
            "Epoch 2/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.9599 - loss: 0.1308 - val_accuracy: 0.9823 - val_loss: 0.0621\n",
            "Epoch 3/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 88ms/step - accuracy: 0.9721 - loss: 0.0921 - val_accuracy: 0.9867 - val_loss: 0.0461\n",
            "Epoch 4/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.9753 - loss: 0.0790 - val_accuracy: 0.9872 - val_loss: 0.0426\n",
            "Epoch 5/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9791 - loss: 0.0668 - val_accuracy: 0.9898 - val_loss: 0.0384\n",
            "Epoch 6/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 88ms/step - accuracy: 0.9813 - loss: 0.0626 - val_accuracy: 0.9908 - val_loss: 0.0351\n",
            "Epoch 7/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 84ms/step - accuracy: 0.9825 - loss: 0.0540 - val_accuracy: 0.9913 - val_loss: 0.0353\n",
            "Epoch 8/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 91ms/step - accuracy: 0.9845 - loss: 0.0499 - val_accuracy: 0.9912 - val_loss: 0.0319\n",
            "Epoch 9/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 87ms/step - accuracy: 0.9854 - loss: 0.0465 - val_accuracy: 0.9912 - val_loss: 0.0309\n",
            "Epoch 10/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9857 - loss: 0.0444 - val_accuracy: 0.9912 - val_loss: 0.0301\n",
            "Epoch 11/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9863 - loss: 0.0441 - val_accuracy: 0.9910 - val_loss: 0.0311\n",
            "Epoch 12/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - accuracy: 0.9880 - loss: 0.0383 - val_accuracy: 0.9922 - val_loss: 0.0302\n",
            "Epoch 13/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9877 - loss: 0.0377 - val_accuracy: 0.9930 - val_loss: 0.0280\n",
            "Epoch 14/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9876 - loss: 0.0370 - val_accuracy: 0.9923 - val_loss: 0.0268\n",
            "Epoch 15/15\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 90ms/step - accuracy: 0.9892 - loss: 0.0328 - val_accuracy: 0.9928 - val_loss: 0.0268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa812ccc1a0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "UtpZIbTHyabN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58e3aaa-0e38-4061-9cdf-7fb9438ca80d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Training Parameters:**\n",
        "\n",
        "*   **`batch_size`:** This determines the number of training samples processed in each mini-batch during training. A larger batch size can speed up training but might require more memory. A smaller batch size can lead to more noisy updates but might generalize better.\n",
        "*   **`epochs`:**  One epoch represents one complete pass through the entire training dataset.  More epochs can potentially lead to better training but also increase the risk of overfitting, where the model learns the training data too well and performs poorly on unseen data.\n",
        "*   **`validation_split=0.1`:**  This reserves 10% of the training data as a validation set. During training, the model's performance is evaluated on this validation set after each epoch. This helps to monitor for overfitting and tune hyperparameters.\n",
        "\n",
        "## Section 6: Model Evaluation - Assessing Performance on Test Data\n",
        "\n",
        "After training, we need to evaluate our model's performance on the test dataset.  This gives us an estimate of how well the model generalizes to unseen data.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Run the code cell below.**\n",
        "2.  **Observe the output.**  It will print the test loss and test accuracy.\n",
        "3.  **Think about the results.** Is the test accuracy satisfactory?  How does it compare to the training and validation accuracy you observed during training?"
      ],
      "metadata": {
        "id": "6FW7k1KMyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Model Evaluation\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0246\n",
            "Test accuracy: 0.9921\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "f3KehXAlyabO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dced3cf9-99c8-4d83-e98c-539ad76e2820"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 7: Reflection and Answers to Questions\n",
        "This is an important section! Take some time to reflect on what you have learned and answer the following questions in detail. Your thoughtful answers will demonstrate your understanding of the concepts covered in this assignment.\n",
        "\n",
        "**Reflection Questions:**\n",
        "\n",
        "1.  **Conv2D Layer:** What is the role of the Conv2D layer? How do the kernel_size and the number of filters affect the learning process? *Hint: Experiment by changing these values in Cell 3.*\n",
        "\n",
        "The Conv2D layer is responsible for learning spatial patterns in the input images. Each filter scans across the image and activates when it detects certain local features, such as edges, curves, or textures. The kernel_size determines the size of the window used to extract these features, with 3x3 being a common choice because it is small enough to capture fine details while still preserving important spatial information. The number of filters determines how many different types of features the model can learn at each layer. Increasing the number of filters generally allows the network to capture more complex patterns, especially in deeper layers.\n",
        "\n",
        "2.  **MaxPooling2D Layer:** What is the purpose of the MaxPooling2D layer? How does it contribute to the model's performance?  *Hint:  Try removing or adding a MaxPooling2D layer and see what happens.*\n",
        "\n",
        "The MaxPooling2D layer reduces the spatial dimensions of the feature maps by keeping only the most activated value within each pooling window. This process helps the model become more robust to small shifts or distortions in the input. Pooling also reduces the total number of parameters and computations, which prevents overfitting and improves training efficiency. Removing MaxPooling layers usually leads to slower training and a higher risk of memorizing noise rather than learning generalizable patterns.\n",
        "\n",
        "3.  **One-Hot Encoding:** Why do we use one-hot encoding for the labels?\n",
        "\n",
        "One-hot encoding converts categorical labels into vectors of equal length where only the index of the correct class is marked as 1. Because the model uses a softmax output layer that returns probability distributions across all classes, one-hot encoded labels match this format and allow the categorical cross-entropy loss function to measure the difference between predicted and true distributions correctly. Without one-hot encoding, the model would not be able to compute the appropriate loss for multi-class classification.\n",
        "\n",
        "4.  **Flatten Layer:** Why do we need the Flatten layer before the Dense layer?\n",
        "\n",
        "The Flatten layer converts the multidimensional feature maps from the convolutional and pooling layers into a 1-dimensional vector. Dense layers expect 1-D inputs, so flattening is necessary to connect the high-level features extracted by the CNN to the fully connected classification layers. Without Flatten, the Dense layer would not understand how to process the spatial feature maps.\n",
        "\n",
        "5.  **Optimizer and Loss Function:** What optimizer and loss function did you choose in Cell 4? Explain your choices.  Why is categorical cross-entropy a suitable loss function for this task?  Why is Adam a good choice of optimiser?\n",
        "\n",
        "For this task, I used categorical_crossentropy as the loss function because it is the standard choice for multi-class classification problems with one-hot encoded labels. It measures how different the predicted probability distribution is from the correct distribution. I chose the Adam optimizer because it adapts the learning rate automatically, converges quickly, and performs well on most deep learning tasks without extensive tuning. Adam also combines the advantages of momentum and adaptive learning rate methods, making it a strong default choice for training CNNs.\n",
        "\n",
        "6.  **Batch Size and Epochs:** How did you choose the batch size and number of epochs in Cell 5? What are the effects of changing these parameters?  *Hint:  Experiment!*\n",
        "\n",
        "I chose a batch size of 128 and trained for 15 epochs. A batch size of 128 provides a balance between stable gradient updates and efficient computation. Training for 15 epochs allows the model to converge without overfitting too quickly. When I experimented with different values, smaller batch sizes produced noisier training curves but sometimes slightly better generalization, while larger batch sizes trained more smoothly but required more memory. Increasing the number of epochs improved accuracy up to a point but eventually led to overfitting, confirming that training for too long can harm performance on new data.\n",
        "\n",
        "7.  **Dropout:**  Why is the Dropout layer included in the model?\n",
        "\n",
        "Dropout randomly disables a fraction of neurons during training, which forces the network to learn more robust feature representations instead of relying too heavily on any specific activation. This significantly reduces overfitting, especially in the Dense layers, which tend to have many parameters. Including a Dropout layer helps the model generalize better to unseen images.\n",
        "\n",
        "8.  **Model Architecture:**  Describe the overall architecture of your CNN. How many convolutional layers did you use?  How many max pooling layers?  What is the final dense layer doing?\n",
        "\n",
        "My CNN consists of two convolutional layers followed by max pooling layers. The first Conv2D layer has 32 filters, and the second has 64 filters. After the convolutional blocks, the feature maps are flattened and passed into a Dropout layer with a rate of 0.5 to reduce overfitting. Finally, a Dense layer with 10 units and a softmax activation outputs the probability distribution over the 10 digit classes. This structure combines feature extraction through convolution with classification through fully connected layers.\n",
        "\n",
        "9.  **Performance:** What accuracy did you achieve on the test set?  Are you happy with the result? Why or why not?  If you're not happy, what could you try to improve the performance?\n",
        "\n",
        "The model achieved a high accuracy on the test set, typically around 99.21% or higher. I am satisfied with this result because MNIST is a well-studied dataset, and a CNN of this size is expected to perform very well. If I wanted to improve the accuracy further, I could experiment with additional convolutional layers, use data augmentation, adjust the dropout rate, or try more advanced architectures such as batch normalization or deeper networks. However, for this assignment, the performance is strong and demonstrates that the model learned meaningful patterns.\n",
        "\n",
        "**Tips and Explanations:**\n",
        "\n",
        "*   **Normalization:**  Dividing the pixel values by 255 normalizes them to the range [0, 1]. This is important for training neural networks.\n",
        "\n",
        "*   **Reshaping:**  The `reshape` operation adds a channel dimension to the images.  For grayscale images, the channel dimension is 1.\n",
        "\n",
        "*   **One-Hot Encoding:** `to_categorical` converts the class labels (0-9) into one-hot encoded vectors.\n",
        "\n",
        "*   **Conv2D Parameters:** The `kernel_size` determines the size of the convolutional filter (e.g., 3x3). The number of filters determines how many different features are learned.\n",
        "\n",
        "*   **MaxPooling2D Parameters:** The `pool_size` determines the size of the pooling window (e.g., 2x2).\n",
        "\n",
        "*   **Optimizer:** The optimizer is the algorithm used to update the model's weights during training.\n",
        "\n",
        "*   **Loss Function:** The loss function measures the error between the model's predictions and the true labels.\n",
        "\n",
        "*   **Batch Size:** The batch size is the number of samples processed in each training iteration.\n",
        "\n",
        "*   **Epochs:** An epoch is one complete pass through the entire training dataset.\n",
        "\n",
        "*   **Dropout:** Dropout is a regularization technique that helps prevent overfitting.\n",
        "\n",
        "Remember to run each cell to see its output.  Experiment with the code and try to understand how different parameters affect the model's performance.  Good luck!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VL_6FT9K5bBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Submission\n",
        " Congratulations on completing this notebook assignment! You have successfully built and trained a Convolutional Neural\n",
        " Network to classify handwritten digits from the MNIST dataset. You've explored key concepts like convolutional layers, pooling layers, activation functions, optimizers, loss functions, and training procedures. To further solidify your understanding, consider the following:\n",
        "*   **Review your notebook:** Go back through each section, reread the explanations, and make sure you understand the code and the concepts.\n",
        "*   **Experiment further:** Try different CNN architectures, add more layers, change hyperparameters, and see how it affects the performance. Explore other optimizers or loss functions.\n",
        "*   **Reflect on your learning:**  Think about the challenges you faced and how you overcame them. What were the most important takeaways for you from this assignment?\n",
        "\n",
        "**Submission Instructions**\n",
        "\n",
        "To submit your assignment:\n",
        "\n",
        "1.  **Save your notebook:** Ensure all your work, including code cells, outputs, and answers to reflection questions, is saved in the notebook.\n",
        "2.  **Print the notebook as a `.pdf` file** and submit it to Canvas.\n",
        "\n",
        "**Deadline:** February, 12th"
      ],
      "metadata": {
        "id": "e9_VbuuK6MFg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}